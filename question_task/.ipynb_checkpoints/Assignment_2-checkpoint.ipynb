{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define a function to analyze a numpy array\n",
    " - Assume we have an array (with shape (M,N)) which contains term frequency of each document, where each row is a document, each column is a word, and the corresponding value denotes the frequency of the word in the document. Define a function named \"analyze_tf_idf\" which:\n",
    "      * takes the **array**, and an integer **K** as the parameters.\n",
    "      * normalizes the frequency of each word as: word frequency divided by the length of the document. Save the result as an array named **tf** (i.e. term frequency)\n",
    "      * calculates the document frequency (**df**) of each word, e.g. how many documents contain a specific word\n",
    "      * calculates **tf_idf** array as: **tf / (log(df)+1)** (tf divided by log(df)). The reason is, if a word appears in most documents, it does not have the discriminative power and often is called a \"stop\" word. The inverse of df can downgrade the weight of such words.\n",
    "      * for each document, finds out the **indexes of words with top K largest values in the tf_idf array**, ($0<K<=N$). These indexes form an array, say **top_K**, with shape (M, K)\n",
    "      * returns the tf_idf array, and the top_K array.\n",
    " - Note, for all the steps, ** do not use any loop**. Just use array functions and broadcasting for high performance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a function to analyze stackoverflow dataset using pandas\n",
    " - Define a function named \"analyze_data\" to do the follows:\n",
    "   * Take a csv file path string as an input. Assume the csv file is in the format of the provided sample file (question.csv).\n",
    "   * Read the csv file as a dataframe with the first row as column names\n",
    "   * Find questions with top 3 viewcounts among those answered questions (i.e answercount>0). Print the title and viewcount columns of these questions.\n",
    "   * Find the top 5 users (i.e. quest_name) who asked the most questions.\n",
    "   * Create a new column called \"first_tag\" to store the very first tag in the \"tags\" column (hint: use \"apply\" function; tags are separted by \", \")\n",
    "   * Show the mean, min, and max viewcount values for each of these tags: \"python\", \"pandas\" and \"dataframe\"\n",
    "   * Create a cross tab with answercount as row indexes, first_tag as column names, and the count of samples as the value. For \"python\" question (i.e. first_tag=\"python\"), how many questions were not answered (i.e., answercount=0), how many questions were answered once (i.e., answercount=1), and how many questions were anasered twice  (i.e., answercount=2)? Print these numbers.\n",
    " - This function does not have any return. Just print out the result of each calculation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (Bonus). Analyzed a collection of documents\n",
    " - Define a function named \"analyze_corpus\" to do the follows:\n",
    "   * Similar to Q2, take a csv file path string as an input. Assume the csv file is in the format of the provided sample file (question.csv).\n",
    "   * Read the \"title\" column from the csv file and convert it to lower case\n",
    "   * Split each string in the \"title\" column by space to get tokens. Create an array where each row represents a title, each column denotes a unique token, and each value denotes the count of the token in the document\n",
    "   * Call your function in Q1 (i.e. analyze_tf_idf) to analyze this array\n",
    "   * Print out the top 5 words by tf-idf score for the first 20 questions. Do you think these top words allow you to find similar questions or differentiate a question from dissimilar ones? Write your analysis as a pdf file.\n",
    "   \n",
    "- This function does not have any return. Just print out the result if asked.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Guideline##\n",
    "- Following the solution template provided below. Use __main__ block to test your functions\n",
    "- Save your code into a python file (e.g. assign2.py) that can be run in a python 3 environment. In Jupyter Notebook, you can export notebook as .py file in menu \"File->Download as\".\n",
    "- Make sure you have all import statements. To test your code, open a command window in your current python working folder, type \"python assign2.py\" to see if it can run successfully.\n",
    "- **Each homework assignment should be completed independently. Never ever copy others' work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure of your solution to Assignment 1 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def analyze_data(filepath):\n",
    "    \n",
    "    # add your code here\n",
    "\n",
    "    \n",
    "    \n",
    "def analyze_tf_idf(arr,K):\n",
    "    \n",
    "    tf_ifd=None\n",
    "    top_k=None\n",
    "    \n",
    "    # add your code here     \n",
    "  \n",
    "    return tf_idf, top_k\n",
    "\n",
    "\n",
    "def analyze_corpus(filepath):\n",
    "    \n",
    "    # add your code here\n",
    "   \n",
    "\n",
    "\n",
    "# best practice to test your class\n",
    "# if your script is exported as a module,\n",
    "# the following part is ignored\n",
    "# this is equivalent to main() in Java\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Question 1\n",
    "    arr=np.array([[0,1,0,2,0,1],[1,0,1,1,2,0],[0,0,2,0,0,1]])\n",
    "    \n",
    "    print(\"\\nQ1\")\n",
    "    tf_idf, top_k=analyze_tf_idf(arr,3)\n",
    "    print(top_k)\n",
    "    \n",
    "    print(\"\\nQ2\")\n",
    "    print(analyze_data('question.csv'))\n",
    "    \n",
    "    # test question 3\n",
    "    print(\"\\nQ3\")\n",
    "    analyze_corpus('question.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
